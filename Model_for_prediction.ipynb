{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import History\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average, Dense\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax\n",
    "from keras import metrics\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "from keras.layers import LSTM \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\image\\\\data\\\\\"\n",
    "\n",
    "df_path = os.path.join(path, 'complete_data.csv')\n",
    "df_test_path = os.path.join(path, 'test_weather_data.csv')\n",
    "\n",
    "df = pd.read_csv(df_path)\n",
    "df = df.dropna()\n",
    "\n",
    "df_test = pd.read_csv(df_test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['month'] = pd.to_datetime(df.datetime).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = pd.to_datetime(df.datetime).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df.datetime).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>kWh</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 0:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.19</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 0:30</td>\n",
       "      <td>2310.732265</td>\n",
       "      <td>30.19</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 1:00</td>\n",
       "      <td>2289.332265</td>\n",
       "      <td>30.16</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 1:30</td>\n",
       "      <td>2314.583265</td>\n",
       "      <td>30.16</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 2:00</td>\n",
       "      <td>2309.308265</td>\n",
       "      <td>30.13</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          datetime          kWh  pressure  temperature  wind_speed  month  \\\n",
       "0  2017-01-01 0:00     0.000000     30.19         46.0        10.0      1   \n",
       "1  2017-01-01 0:30  2310.732265     30.19         45.0         7.0      1   \n",
       "2  2017-01-01 1:00  2289.332265     30.16         45.0         6.0      1   \n",
       "3  2017-01-01 1:30  2314.583265     30.16         45.0         7.0      1   \n",
       "4  2017-01-01 2:00  2309.308265     30.13         45.0        10.0      1   \n",
       "\n",
       "   weekday  year  \n",
       "0        6  2017  \n",
       "1        6  2017  \n",
       "2        6  2017  \n",
       "3        6  2017  \n",
       "4        6  2017  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df[['month', 'year', 'pressure', 'temperature', 'wind_speed']][:25000]\n",
    "y_train = df['kWh'][:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = df[['month', 'year', 'pressure', 'temperature', 'wind_speed']][25000:30000]\n",
    "y_val = df['kWh'][25000:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df[['month', 'year', 'pressure', 'temperature', 'wind_speed']][30000:31000]\n",
    "y_test = df['kWh'][30000:31000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "sc = MinMaxScaler()\n",
    "\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_strength = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_learning_model_1(x_size, y_size):\n",
    "    t_model = Sequential()\n",
    "    t_model.add(Dense(5, activation=\"relu\", kernel_regularizer=regularizers.l2(regularization_strength), input_shape=(x_size,)))\n",
    "    t_model.add(BatchNormalization())\n",
    "    t_model.add(Dense(3, activation=\"relu\", kernel_regularizer=regularizers.l2(regularization_strength)))\n",
    "    t_model.add(BatchNormalization())\n",
    "    t_model.add(Dense(y_size))\n",
    "    print(t_model.summary())\n",
    "    t_model.compile(loss='mean_squared_error',\n",
    "        optimizer=Adam(lr=1e-3, decay=0.0),\n",
    "        metrics=['accuracy'])\n",
    "    return(t_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 5)                 35        \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 73\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = deep_learning_model_1(x_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  150\n",
      "Batch size:  10\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "batch_size = 10\n",
    "\n",
    "print('Epochs: ', epochs)\n",
    "print('Batch size: ', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/150\n",
      "25000/25000 [==============================] - 3s 136us/step - loss: 10089413.8016 - acc: 0.0000e+00 - val_loss: 9710841.6110 - val_acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 9618480.5810 - acc: 0.0000e+00 - val_loss: 9241538.9390 - val_acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 8881657.5240 - acc: 0.0000e+00 - val_loss: 8580602.7410 - val_acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 7957514.3694 - acc: 0.0000e+00 - val_loss: 7570063.0615 - val_acc: 0.0000e+00\n",
      "Epoch 5/150\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 6892609.2920 - acc: 0.0000e+00 - val_loss: 6317574.8235 - val_acc: 0.0000e+00\n",
      "Epoch 6/150\n",
      "25000/25000 [==============================] - 3s 110us/step - loss: 5738253.7262 - acc: 0.0000e+00 - val_loss: 5154315.9835 - val_acc: 0.0000e+00\n",
      "Epoch 7/150\n",
      "25000/25000 [==============================] - 3s 118us/step - loss: 4554566.4372 - acc: 0.0000e+00 - val_loss: 4055108.8525 - val_acc: 0.0000e+00\n",
      "Epoch 8/150\n",
      "25000/25000 [==============================] - 3s 113us/step - loss: 3403504.4574 - acc: 0.0000e+00 - val_loss: 2964827.0850 - val_acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 2352316.4841 - acc: 0.0000e+00 - val_loss: 1901180.6550 - val_acc: 0.0000e+00\n",
      "Epoch 10/150\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 1467381.1834 - acc: 0.0000e+00 - val_loss: 1127166.4936 - val_acc: 0.0000e+00\n",
      "Epoch 11/150\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 809158.2974 - acc: 0.0000e+00 - val_loss: 597068.7686 - val_acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 422548.8738 - acc: 0.0000e+00 - val_loss: 288453.7201 - val_acc: 0.0000e+00\n",
      "Epoch 13/150\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 281111.7066 - acc: 0.0000e+00 - val_loss: 241292.7868 - val_acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 261866.8442 - acc: 4.0000e-05 - val_loss: 237023.3080 - val_acc: 0.0000e+00\n",
      "Epoch 15/150\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 261649.2368 - acc: 0.0000e+00 - val_loss: 221349.7130 - val_acc: 0.0000e+00\n",
      "Epoch 16/150\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 261811.8971 - acc: 0.0000e+00 - val_loss: 225883.3792 - val_acc: 0.0000e+00\n",
      "Epoch 17/150\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 260318.3401 - acc: 0.0000e+00 - val_loss: 230464.1746 - val_acc: 0.0000e+00\n",
      "Epoch 18/150\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 260627.9833 - acc: 0.0000e+00 - val_loss: 232750.9456 - val_acc: 0.0000e+00\n",
      "Epoch 19/150\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 259153.5681 - acc: 0.0000e+00 - val_loss: 244488.7441 - val_acc: 2.0000e-04\n",
      "Epoch 20/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 259752.4005 - acc: 0.0000e+00 - val_loss: 231334.3074 - val_acc: 0.0000e+00\n",
      "Epoch 21/150\n",
      "25000/25000 [==============================] - 3s 115us/step - loss: 260258.5967 - acc: 0.0000e+00 - val_loss: 225504.9041 - val_acc: 0.0000e+00\n",
      "Epoch 22/150\n",
      "25000/25000 [==============================] - 3s 116us/step - loss: 259838.8844 - acc: 0.0000e+00 - val_loss: 226664.3714 - val_acc: 0.0000e+00\n",
      "Epoch 23/150\n",
      "25000/25000 [==============================] - 3s 114us/step - loss: 259335.1212 - acc: 0.0000e+00 - val_loss: 221428.9394 - val_acc: 0.0000e+00\n",
      "Epoch 24/150\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 259193.3681 - acc: 0.0000e+00 - val_loss: 232431.6832 - val_acc: 0.0000e+00\n",
      "Epoch 25/150\n",
      "25000/25000 [==============================] - 2s 97us/step - loss: 259583.6243 - acc: 0.0000e+00 - val_loss: 226132.5980 - val_acc: 0.0000e+00\n",
      "Epoch 26/150\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 259084.3796 - acc: 0.0000e+00 - val_loss: 227890.6267 - val_acc: 0.0000e+00\n",
      "Epoch 27/150\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 260482.2325 - acc: 0.0000e+00 - val_loss: 223812.6751 - val_acc: 0.0000e+00\n",
      "Epoch 28/150\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 258232.3228 - acc: 0.0000e+00 - val_loss: 217340.6169 - val_acc: 0.0000e+00\n",
      "Epoch 29/150\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 259962.9404 - acc: 0.0000e+00 - val_loss: 223758.6714 - val_acc: 0.0000e+00\n",
      "Epoch 30/150\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 258695.1332 - acc: 0.0000e+00 - val_loss: 223369.2002 - val_acc: 0.0000e+00\n",
      "Epoch 31/150\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 260347.0871 - acc: 0.0000e+00 - val_loss: 220688.4970 - val_acc: 0.0000e+00\n",
      "Epoch 32/150\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 259377.7889 - acc: 0.0000e+00 - val_loss: 224543.1077 - val_acc: 0.0000e+00\n",
      "Epoch 33/150\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 258538.9567 - acc: 0.0000e+00 - val_loss: 222699.1095 - val_acc: 0.0000e+00\n",
      "Epoch 34/150\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 259054.0021 - acc: 0.0000e+00 - val_loss: 222464.8638 - val_acc: 0.0000e+00\n",
      "Epoch 35/150\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 259487.4524 - acc: 0.0000e+00 - val_loss: 220669.0955 - val_acc: 0.0000e+00\n",
      "Epoch 36/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 258738.3142 - acc: 0.0000e+00 - val_loss: 226610.0773 - val_acc: 0.0000e+00\n",
      "Epoch 37/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 258968.9908 - acc: 0.0000e+00 - val_loss: 223858.8597 - val_acc: 0.0000e+00\n",
      "Epoch 38/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 259235.7101 - acc: 0.0000e+00 - val_loss: 218641.0524 - val_acc: 0.0000e+00\n",
      "Epoch 39/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 258544.6153 - acc: 0.0000e+00 - val_loss: 218560.2419 - val_acc: 0.0000e+00\n",
      "Epoch 40/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 257804.5067 - acc: 0.0000e+00 - val_loss: 218662.7935 - val_acc: 0.0000e+00\n",
      "Epoch 41/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 257974.9360 - acc: 0.0000e+00 - val_loss: 223310.7347 - val_acc: 0.0000e+00\n",
      "Epoch 42/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 256724.1301 - acc: 0.0000e+00 - val_loss: 219338.6628 - val_acc: 0.0000e+00\n",
      "Epoch 43/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 257171.1167 - acc: 0.0000e+00 - val_loss: 216821.6799 - val_acc: 0.0000e+00\n",
      "Epoch 44/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 257876.7482 - acc: 0.0000e+00 - val_loss: 214266.6748 - val_acc: 0.0000e+00\n",
      "Epoch 45/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 258736.8064 - acc: 0.0000e+00 - val_loss: 217763.3553 - val_acc: 0.0000e+00\n",
      "Epoch 46/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 257900.7348 - acc: 4.0000e-05 - val_loss: 213790.4644 - val_acc: 0.0000e+00\n",
      "Epoch 47/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 257304.2784 - acc: 0.0000e+00 - val_loss: 222560.9089 - val_acc: 0.0000e+00\n",
      "Epoch 48/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 257629.1575 - acc: 0.0000e+00 - val_loss: 213879.1944 - val_acc: 0.0000e+00\n",
      "Epoch 49/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 257751.9923 - acc: 0.0000e+00 - val_loss: 217559.3575 - val_acc: 0.0000e+00\n",
      "Epoch 50/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 257964.6063 - acc: 0.0000e+00 - val_loss: 221232.4947 - val_acc: 2.0000e-04\n",
      "Epoch 51/150\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 256791.8802 - acc: 0.0000e+00 - val_loss: 227670.2425 - val_acc: 0.0000e+00\n",
      "Epoch 52/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 257873.6238 - acc: 0.0000e+00 - val_loss: 229899.1939 - val_acc: 0.0000e+00\n",
      "Epoch 53/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 257370.0913 - acc: 0.0000e+00 - val_loss: 227303.1340 - val_acc: 0.0000e+00\n",
      "Epoch 54/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 256627.0706 - acc: 0.0000e+00 - val_loss: 218141.9650 - val_acc: 0.0000e+00\n",
      "Epoch 55/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 257024.4849 - acc: 0.0000e+00 - val_loss: 218919.9952 - val_acc: 0.0000e+00\n",
      "Epoch 56/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 256155.9487 - acc: 0.0000e+00 - val_loss: 223540.7886 - val_acc: 0.0000e+00\n",
      "Epoch 57/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 256905.9021 - acc: 0.0000e+00 - val_loss: 220175.2140 - val_acc: 0.0000e+00\n",
      "Epoch 58/150\n",
      "25000/25000 [==============================] - 3s 110us/step - loss: 255931.8907 - acc: 0.0000e+00 - val_loss: 222744.3732 - val_acc: 0.0000e+00\n",
      "Epoch 59/150\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 255549.4677 - acc: 0.0000e+00 - val_loss: 223857.8102 - val_acc: 0.0000e+00\n",
      "Epoch 60/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 256137.7090 - acc: 0.0000e+00 - val_loss: 213752.9719 - val_acc: 0.0000e+00\n",
      "Epoch 61/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 256227.7572 - acc: 0.0000e+00 - val_loss: 222132.8084 - val_acc: 0.0000e+00\n",
      "Epoch 62/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 255760.4868 - acc: 0.0000e+00 - val_loss: 218727.9875 - val_acc: 0.0000e+00\n",
      "Epoch 63/150\n",
      "25000/25000 [==============================] - 3s 108us/step - loss: 256184.1288 - acc: 0.0000e+00 - val_loss: 214923.0454 - val_acc: 0.0000e+00\n",
      "Epoch 64/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 255780.0538 - acc: 0.0000e+00 - val_loss: 229657.2923 - val_acc: 0.0000e+00\n",
      "Epoch 65/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 255203.0991 - acc: 0.0000e+00 - val_loss: 220687.4715 - val_acc: 0.0000e+00\n",
      "Epoch 66/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 255651.2820 - acc: 4.0000e-05 - val_loss: 214342.9716 - val_acc: 0.0000e+00\n",
      "Epoch 67/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 255268.5032 - acc: 0.0000e+00 - val_loss: 226288.4072 - val_acc: 0.0000e+00\n",
      "Epoch 68/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 255716.9465 - acc: 0.0000e+00 - val_loss: 223359.6659 - val_acc: 0.0000e+00\n",
      "Epoch 69/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 255590.7625 - acc: 0.0000e+00 - val_loss: 222565.1699 - val_acc: 0.0000e+00\n",
      "Epoch 70/150\n",
      "25000/25000 [==============================] - 3s 104us/step - loss: 255515.0199 - acc: 0.0000e+00 - val_loss: 220251.1061 - val_acc: 0.0000e+00\n",
      "Epoch 71/150\n",
      "25000/25000 [==============================] - 3s 118us/step - loss: 255804.0643 - acc: 0.0000e+00 - val_loss: 225748.8448 - val_acc: 0.0000e+00\n",
      "Epoch 72/150\n",
      "25000/25000 [==============================] - 3s 117us/step - loss: 255156.2575 - acc: 0.0000e+00 - val_loss: 223767.3629 - val_acc: 2.0000e-04\n",
      "Epoch 73/150\n",
      "25000/25000 [==============================] - 3s 112us/step - loss: 255635.8074 - acc: 0.0000e+00 - val_loss: 222262.5903 - val_acc: 0.0000e+00\n",
      "Epoch 74/150\n",
      "25000/25000 [==============================] - 3s 111us/step - loss: 255328.2144 - acc: 0.0000e+00 - val_loss: 225613.6392 - val_acc: 0.0000e+00\n",
      "Epoch 75/150\n",
      "25000/25000 [==============================] - 3s 111us/step - loss: 254829.2666 - acc: 0.0000e+00 - val_loss: 226153.8678 - val_acc: 0.0000e+00\n",
      "Epoch 76/150\n",
      "25000/25000 [==============================] - 3s 113us/step - loss: 254775.0718 - acc: 0.0000e+00 - val_loss: 224406.3376 - val_acc: 0.0000e+00\n",
      "Epoch 77/150\n",
      "25000/25000 [==============================] - 3s 115us/step - loss: 254271.2514 - acc: 0.0000e+00 - val_loss: 226814.7436 - val_acc: 0.0000e+00\n",
      "Epoch 78/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 254497.7353 - acc: 0.0000e+00 - val_loss: 226818.1690 - val_acc: 0.0000e+00\n",
      "Epoch 79/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 254479.4719 - acc: 0.0000e+00 - val_loss: 228527.5345 - val_acc: 0.0000e+00\n",
      "Epoch 80/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 255228.1509 - acc: 0.0000e+00 - val_loss: 230334.8264 - val_acc: 0.0000e+00\n",
      "Epoch 81/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 254818.0660 - acc: 0.0000e+00 - val_loss: 227442.3304 - val_acc: 0.0000e+00\n",
      "Epoch 82/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 255419.7511 - acc: 0.0000e+00 - val_loss: 232182.2732 - val_acc: 0.0000e+00\n",
      "Epoch 83/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 255785.0110 - acc: 0.0000e+00 - val_loss: 230104.1222 - val_acc: 0.0000e+00\n",
      "Epoch 84/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 253987.2048 - acc: 4.0000e-05 - val_loss: 230602.7361 - val_acc: 2.0000e-04\n",
      "Epoch 85/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 254904.3051 - acc: 0.0000e+00 - val_loss: 227232.7034 - val_acc: 0.0000e+00\n",
      "Epoch 86/150\n",
      "25000/25000 [==============================] - 3s 113us/step - loss: 254176.1754 - acc: 0.0000e+00 - val_loss: 224315.4439 - val_acc: 2.0000e-04\n",
      "Epoch 87/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 254475.6871 - acc: 4.0000e-05 - val_loss: 231797.1991 - val_acc: 0.0000e+00\n",
      "Epoch 88/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 254089.4878 - acc: 0.0000e+00 - val_loss: 234562.6189 - val_acc: 0.0000e+00\n",
      "Epoch 89/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 253571.6315 - acc: 0.0000e+00 - val_loss: 228702.3514 - val_acc: 0.0000e+00\n",
      "Epoch 90/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 254648.9947 - acc: 0.0000e+00 - val_loss: 230697.1426 - val_acc: 0.0000e+00\n",
      "Epoch 91/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 254317.8502 - acc: 0.0000e+00 - val_loss: 238986.2436 - val_acc: 0.0000e+00\n",
      "Epoch 92/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 253825.1815 - acc: 0.0000e+00 - val_loss: 237158.9647 - val_acc: 0.0000e+00\n",
      "Epoch 93/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 253616.4912 - acc: 0.0000e+00 - val_loss: 230497.3806 - val_acc: 0.0000e+00\n",
      "Epoch 94/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 254964.8148 - acc: 0.0000e+00 - val_loss: 231873.3117 - val_acc: 0.0000e+00\n",
      "Epoch 95/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 253500.0235 - acc: 0.0000e+00 - val_loss: 231185.7552 - val_acc: 0.0000e+00\n",
      "Epoch 96/150\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 253472.7309 - acc: 0.0000e+00 - val_loss: 231791.9577 - val_acc: 0.0000e+00\n",
      "Epoch 97/150\n",
      "25000/25000 [==============================] - 3s 109us/step - loss: 253694.1922 - acc: 0.0000e+00 - val_loss: 231764.0853 - val_acc: 0.0000e+00\n",
      "Epoch 98/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 253115.1549 - acc: 0.0000e+00 - val_loss: 232092.0709 - val_acc: 0.0000e+00\n",
      "Epoch 99/150\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 253516.3029 - acc: 0.0000e+00 - val_loss: 236507.9035 - val_acc: 0.0000e+00\n",
      "Epoch 100/150\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 253056.7149 - acc: 0.0000e+00 - val_loss: 244247.4781 - val_acc: 0.0000e+00\n",
      "Epoch 101/150\n",
      "25000/25000 [==============================] - 3s 103us/step - loss: 254687.3038 - acc: 0.0000e+00 - val_loss: 241917.6729 - val_acc: 0.0000e+00\n",
      "Epoch 102/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 252217.3679 - acc: 4.0000e-05 - val_loss: 235433.2464 - val_acc: 0.0000e+00\n",
      "Epoch 103/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 253822.8784 - acc: 0.0000e+00 - val_loss: 236384.1454 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/150\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 253411.0897 - acc: 0.0000e+00 - val_loss: 240409.7012 - val_acc: 0.0000e+00\n",
      "Epoch 105/150\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 253395.3815 - acc: 0.0000e+00 - val_loss: 238419.4634 - val_acc: 0.0000e+00\n",
      "Epoch 106/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 254187.9712 - acc: 0.0000e+00 - val_loss: 231581.1845 - val_acc: 0.0000e+00\n",
      "Epoch 107/150\n",
      "25000/25000 [==============================] - 2s 99us/step - loss: 252082.9709 - acc: 0.0000e+00 - val_loss: 233965.0381 - val_acc: 0.0000e+00\n",
      "Epoch 108/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 252564.8475 - acc: 0.0000e+00 - val_loss: 239313.0786 - val_acc: 0.0000e+00\n",
      "Epoch 109/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 253010.8553 - acc: 0.0000e+00 - val_loss: 243219.8959 - val_acc: 0.0000e+00\n",
      "Epoch 110/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 253111.7377 - acc: 0.0000e+00 - val_loss: 242919.4887 - val_acc: 0.0000e+00\n",
      "Epoch 111/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 253344.4541 - acc: 4.0000e-05 - val_loss: 240500.0065 - val_acc: 0.0000e+00\n",
      "Epoch 112/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 252582.1927 - acc: 0.0000e+00 - val_loss: 235080.7907 - val_acc: 0.0000e+00\n",
      "Epoch 113/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 252961.3465 - acc: 0.0000e+00 - val_loss: 228685.9939 - val_acc: 0.0000e+00\n",
      "Epoch 114/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 252825.9334 - acc: 0.0000e+00 - val_loss: 237287.5606 - val_acc: 0.0000e+00\n",
      "Epoch 115/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 252307.8612 - acc: 0.0000e+00 - val_loss: 235613.2399 - val_acc: 0.0000e+00\n",
      "Epoch 116/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 252256.8764 - acc: 0.0000e+00 - val_loss: 236742.1783 - val_acc: 0.0000e+00\n",
      "Epoch 117/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 254236.6385 - acc: 0.0000e+00 - val_loss: 236235.1065 - val_acc: 0.0000e+00\n",
      "Epoch 118/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 252047.0491 - acc: 0.0000e+00 - val_loss: 231005.8635 - val_acc: 0.0000e+00\n",
      "Epoch 119/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 253086.7122 - acc: 4.0000e-05 - val_loss: 234724.3144 - val_acc: 0.0000e+00\n",
      "Epoch 120/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 252057.6248 - acc: 0.0000e+00 - val_loss: 231893.5150 - val_acc: 0.0000e+00\n",
      "Epoch 121/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 250890.6432 - acc: 0.0000e+00 - val_loss: 232003.4283 - val_acc: 0.0000e+00\n",
      "Epoch 122/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 253032.7390 - acc: 0.0000e+00 - val_loss: 238297.7654 - val_acc: 0.0000e+00\n",
      "Epoch 123/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 252475.8156 - acc: 4.0000e-05 - val_loss: 229044.9747 - val_acc: 0.0000e+00\n",
      "Epoch 124/150\n",
      "25000/25000 [==============================] - 2s 100us/step - loss: 252518.3969 - acc: 0.0000e+00 - val_loss: 237456.2713 - val_acc: 0.0000e+00\n",
      "Epoch 125/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 251837.7100 - acc: 0.0000e+00 - val_loss: 236192.0408 - val_acc: 0.0000e+00\n",
      "Epoch 126/150\n",
      "25000/25000 [==============================] - 3s 100us/step - loss: 253283.5438 - acc: 0.0000e+00 - val_loss: 246819.7347 - val_acc: 0.0000e+00\n",
      "Epoch 127/150\n",
      "25000/25000 [==============================] - 3s 115us/step - loss: 253059.5822 - acc: 0.0000e+00 - val_loss: 226649.3013 - val_acc: 0.0000e+00\n",
      "Epoch 128/150\n",
      "25000/25000 [==============================] - 3s 117us/step - loss: 251724.9953 - acc: 4.0000e-05 - val_loss: 233993.7483 - val_acc: 0.0000e+00\n",
      "Epoch 129/150\n",
      "25000/25000 [==============================] - 3s 116us/step - loss: 252177.7936 - acc: 0.0000e+00 - val_loss: 237898.4621 - val_acc: 0.0000e+00\n",
      "Epoch 130/150\n",
      "25000/25000 [==============================] - 3s 110us/step - loss: 251336.0349 - acc: 0.0000e+00 - val_loss: 229427.8500 - val_acc: 0.0000e+00\n",
      "Epoch 131/150\n",
      "25000/25000 [==============================] - 3s 112us/step - loss: 252153.3458 - acc: 4.0000e-05 - val_loss: 237993.2850 - val_acc: 0.0000e+00\n",
      "Epoch 132/150\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 252687.5003 - acc: 0.0000e+00 - val_loss: 231638.7813 - val_acc: 0.0000e+00\n",
      "Epoch 133/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 252091.7477 - acc: 0.0000e+00 - val_loss: 232195.9373 - val_acc: 0.0000e+00\n",
      "Epoch 134/150\n",
      "25000/25000 [==============================] - 3s 112us/step - loss: 251614.2077 - acc: 0.0000e+00 - val_loss: 241271.5362 - val_acc: 0.0000e+00\n",
      "Epoch 135/150\n",
      "25000/25000 [==============================] - 3s 116us/step - loss: 251547.1862 - acc: 0.0000e+00 - val_loss: 224311.9172 - val_acc: 0.0000e+00\n",
      "Epoch 136/150\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 251556.6369 - acc: 0.0000e+00 - val_loss: 240040.7121 - val_acc: 0.0000e+00\n",
      "Epoch 137/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 251924.0694 - acc: 0.0000e+00 - val_loss: 231866.8794 - val_acc: 0.0000e+00\n",
      "Epoch 138/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 251605.5764 - acc: 0.0000e+00 - val_loss: 231758.7973 - val_acc: 0.0000e+00\n",
      "Epoch 139/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 252658.6144 - acc: 0.0000e+00 - val_loss: 236390.7949 - val_acc: 0.0000e+00\n",
      "Epoch 140/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 252725.4651 - acc: 0.0000e+00 - val_loss: 227954.1142 - val_acc: 0.0000e+00\n",
      "Epoch 141/150\n",
      "25000/25000 [==============================] - 3s 118us/step - loss: 253062.5144 - acc: 0.0000e+00 - val_loss: 235131.0870 - val_acc: 0.0000e+00\n",
      "Epoch 142/150\n",
      "25000/25000 [==============================] - 3s 117us/step - loss: 251105.6465 - acc: 0.0000e+00 - val_loss: 238855.5607 - val_acc: 0.0000e+00\n",
      "Epoch 143/150\n",
      "25000/25000 [==============================] - 3s 118us/step - loss: 251945.5999 - acc: 0.0000e+00 - val_loss: 239834.8287 - val_acc: 0.0000e+00\n",
      "Epoch 144/150\n",
      "25000/25000 [==============================] - 3s 107us/step - loss: 252049.4165 - acc: 0.0000e+00 - val_loss: 234301.0980 - val_acc: 0.0000e+00\n",
      "Epoch 145/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 252501.0894 - acc: 0.0000e+00 - val_loss: 238094.9864 - val_acc: 0.0000e+00\n",
      "Epoch 146/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 252100.0510 - acc: 0.0000e+00 - val_loss: 231265.2427 - val_acc: 0.0000e+00\n",
      "Epoch 147/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 251586.0153 - acc: 0.0000e+00 - val_loss: 228380.1079 - val_acc: 0.0000e+00\n",
      "Epoch 148/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 252179.4739 - acc: 0.0000e+00 - val_loss: 234092.0860 - val_acc: 0.0000e+00\n",
      "Epoch 149/150\n",
      "25000/25000 [==============================] - 3s 101us/step - loss: 251824.3941 - acc: 0.0000e+00 - val_loss: 230907.7144 - val_acc: 0.0000e+00\n",
      "Epoch 150/150\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 252092.8217 - acc: 0.0000e+00 - val_loss: 232145.7234 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=1, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# ‘b’는 파란색 실선을 의미합니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3748.9192]\n",
      " [3897.3623]\n",
      " [3809.7932]\n",
      " [3898.016 ]\n",
      " [3808.9502]\n",
      " [3808.107 ]\n",
      " [3832.7595]\n",
      " [3958.047 ]\n",
      " [3927.515 ]\n",
      " [3927.515 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test[:10])\n",
    "# print(y_pred)\n",
    "print(y_pred + 800)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33101    4148.487000\n",
       "33102    4161.025000\n",
       "33103    4121.763000\n",
       "33104    4129.237000\n",
       "33105    4083.013000\n",
       "33106    4029.075000\n",
       "33107    3931.750000\n",
       "33108    3844.301000\n",
       "33109    3697.486000\n",
       "33110    3612.100462\n",
       "33111    3526.051462\n",
       "33112    3369.875462\n",
       "33113    3280.477462\n",
       "33114    3195.199462\n",
       "33115    3103.077462\n",
       "33116    3038.325462\n",
       "33117    2974.263462\n",
       "33118    2934.400462\n",
       "33119    2838.226462\n",
       "33120    2802.737000\n",
       "33121    2789.812462\n",
       "33122    2797.926462\n",
       "33123    2742.275000\n",
       "33124    2734.436000\n",
       "33125    2719.051000\n",
       "33126    2738.862000\n",
       "33127    2726.712000\n",
       "33128    2697.190000\n",
       "33129    2704.911000\n",
       "33130    2715.451000\n",
       "33133    3086.300000\n",
       "33136    3240.038000\n",
       "33137    3335.662000\n",
       "33138    3483.488000\n",
       "33149    4132.837000\n",
       "33151    4151.051000\n",
       "33152    4124.600000\n",
       "33153    4074.425000\n",
       "33154    3996.063000\n",
       "33155    3903.987000\n",
       "33156    3758.051000\n",
       "33157    3684.399000\n",
       "33158    3552.150000\n",
       "33159    3433.063000\n",
       "33160    3330.837000\n",
       "33161    3239.451000\n",
       "33162    3161.037000\n",
       "33163    3050.025000\n",
       "33164    2992.524000\n",
       "33165    2923.827000\n",
       "Name: kWh, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(model, to_file='test_keras_plot_model.png', show_shapes=True)\n",
    "#IPython.display.Image('test_keras_plot_model.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
